{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: wavenet-lstm-v2-keras/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p wavenet-lstm-v2-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataset  = json.load(open('wavenet-lstm-v2-keras/dataset-metadata.json'))\n",
    "dataset['title'] = 'wavenet-lstm-v2-keras'\n",
    "dataset['id'] = 'jessepinkman21/ion-switching-wavenet-lstm-v2-keras'\n",
    "json.dump(dataset, open('wavenet-lstm-v2-keras/dataset-metadata.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file submission_wavenet.csv\n",
      "100%|██████████████████████████████████████| 21.0M/21.0M [00:05<00:00, 3.71MB/s]\n",
      "Upload successful: submission_wavenet.csv (21MB)\n",
      "Starting upload for file wavenet-lstm-v2-keras.ipynb\n",
      "100%|████████████████████████████████████████| 227k/227k [00:05<00:00, 42.9kB/s]\n",
      "Upload successful: wavenet-lstm-v2-keras.ipynb (227KB)\n",
      "Starting upload for file model_0.tar\n",
      "100%|██████████████████████████████████████| 31.0M/31.0M [00:06<00:00, 5.09MB/s]\n",
      "Upload successful: model_0.tar (31MB)\n",
      "Starting upload for file model_4.tar\n",
      "100%|██████████████████████████████████████| 31.0M/31.0M [00:05<00:00, 6.16MB/s]\n",
      "Upload successful: model_4.tar (31MB)\n",
      "Starting upload for file model_1.tar\n",
      "100%|██████████████████████████████████████| 31.1M/31.1M [00:05<00:00, 6.47MB/s]\n",
      "Upload successful: model_1.tar (31MB)\n",
      "Starting upload for file .ipynb_checkpoints.tar\n",
      "100%|████████████████████████████████████████| 420k/420k [00:04<00:00, 91.7kB/s]\n",
      "Upload successful: .ipynb_checkpoints.tar (420KB)\n",
      "Starting upload for file model_2.tar\n",
      "100%|██████████████████████████████████████| 31.1M/31.1M [00:05<00:00, 6.30MB/s]\n",
      "Upload successful: model_2.tar (31MB)\n",
      "Starting upload for file test_wavenet_probs.npy\n",
      "100%|████████████████████████████████████████| 168M/168M [00:10<00:00, 17.1MB/s]\n",
      "Upload successful: test_wavenet_probs.npy (168MB)\n",
      "Starting upload for file wavenet-lstm-v2-keras-inference.ipynb\n",
      "100%|████████████████████████████████████████| 188k/188k [00:04<00:00, 39.2kB/s]\n",
      "Upload successful: wavenet-lstm-v2-keras-inference.ipynb (188KB)\n",
      "Starting upload for file model_3.tar\n",
      "100%|██████████████████████████████████████| 31.1M/31.1M [00:07<00:00, 4.34MB/s]\n",
      "Upload successful: model_3.tar (31MB)\n",
      "Starting upload for file oof_wavenet_probs.npy\n",
      "100%|████████████████████████████████████████| 420M/420M [00:14<00:00, 30.0MB/s]\n",
      "Upload successful: oof_wavenet_probs.npy (420MB)\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/jessepinkman21/ion-switching-wavenet-lstm-v2-keras\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets version -p wavenet-lstm-v2-keras -r tar -m VERSION_NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: group-autoencoder/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p group-autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataset  = json.load(open('group-autoencoder/dataset-metadata.json'))\n",
    "dataset['title'] = 'group-autoencoder'\n",
    "dataset['id'] = 'jessepinkman21/ion-switching-group-autoencoder'\n",
    "json.dump(dataset, open('group-autoencoder/dataset-metadata.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file oof_enc.npy\n",
      "100%|████████████████████████████████████████| 313k/313k [00:07<00:00, 44.2kB/s]\n",
      "Upload successful: oof_enc.npy (313KB)\n",
      "Starting upload for file model_0.tar\n",
      "100%|████████████████████████████████████████| 532M/532M [00:10<00:00, 51.6MB/s]\n",
      "Upload successful: model_0.tar (532MB)\n",
      "Starting upload for file model_4.tar\n",
      "100%|████████████████████████████████████████| 532M/532M [00:12<00:00, 43.3MB/s]\n",
      "Upload successful: model_4.tar (532MB)\n",
      "Starting upload for file model_1.tar\n",
      "100%|████████████████████████████████████████| 532M/532M [00:10<00:00, 52.8MB/s]\n",
      "Upload successful: model_1.tar (532MB)\n",
      "Starting upload for file oof_dec.npy\n",
      "100%|██████████████████████████████████████| 38.1M/38.1M [00:04<00:00, 8.29MB/s]\n",
      "Upload successful: oof_dec.npy (38MB)\n",
      "Starting upload for file Clustering.ipynb\n",
      "100%|████████████████████████████████████████| 602k/602k [00:06<00:00, 99.9kB/s]\n",
      "Upload successful: Clustering.ipynb (602KB)\n",
      "Starting upload for file .ipynb_checkpoints.tar\n",
      "100%|█████████████████████████████████████████| 990k/990k [00:06<00:00, 168kB/s]\n",
      "Upload successful: .ipynb_checkpoints.tar (990KB)\n",
      "Starting upload for file train.npy\n",
      "100%|██████████████████████████████████████| 38.1M/38.1M [00:06<00:00, 6.26MB/s]\n",
      "Upload successful: train.npy (38MB)\n",
      "Starting upload for file test_dec.npy\n",
      "100%|██████████████████████████████████████| 15.3M/15.3M [00:07<00:00, 2.19MB/s]\n",
      "Upload successful: test_dec.npy (15MB)\n",
      "Starting upload for file encoder_1.tar\n",
      "100%|████████████████████████████████████████| 133M/133M [00:06<00:00, 20.2MB/s]\n",
      "Upload successful: encoder_1.tar (133MB)\n",
      "Starting upload for file conv1d-autoencoder-inference.ipynb\n",
      "100%|██████████████████████████████████████| 51.7k/51.7k [00:04<00:00, 11.1kB/s]\n",
      "Upload successful: conv1d-autoencoder-inference.ipynb (52KB)\n",
      "Starting upload for file encoder_0.tar\n",
      "100%|████████████████████████████████████████| 133M/133M [00:06<00:00, 21.6MB/s]\n",
      "Upload successful: encoder_0.tar (133MB)\n",
      "Starting upload for file encoder_3.tar\n",
      "100%|████████████████████████████████████████| 133M/133M [00:08<00:00, 16.2MB/s]\n",
      "Upload successful: encoder_3.tar (133MB)\n",
      "Starting upload for file spectrogram-autoencoder.ipynb\n",
      "100%|███████████████████████████████████████| 1.88M/1.88M [00:07<00:00, 258kB/s]\n",
      "Upload successful: spectrogram-autoencoder.ipynb (2MB)\n",
      "Starting upload for file model_2.tar\n",
      "100%|████████████████████████████████████████| 532M/532M [00:10<00:00, 53.3MB/s]\n",
      "Upload successful: model_2.tar (532MB)\n",
      "Starting upload for file test_wavenet_probs.npy\n",
      "100%|████████████████████████████████████████| 125k/125k [00:05<00:00, 25.1kB/s]\n",
      "Upload successful: test_wavenet_probs.npy (125KB)\n",
      "Starting upload for file encoder_2.tar\n",
      "100%|████████████████████████████████████████| 133M/133M [00:06<00:00, 20.4MB/s]\n",
      "Upload successful: encoder_2.tar (133MB)\n",
      "Starting upload for file Untitled.ipynb\n",
      "100%|████████████████████████████████████████| 5.25k/5.25k [00:07<00:00, 722B/s]\n",
      "Upload successful: Untitled.ipynb (5KB)\n",
      "Starting upload for file model_3.tar\n",
      "100%|████████████████████████████████████████| 532M/532M [00:10<00:00, 55.3MB/s]\n",
      "Upload successful: model_3.tar (532MB)\n",
      "Starting upload for file encoder_4.tar\n",
      "100%|████████████████████████████████████████| 133M/133M [00:06<00:00, 20.4MB/s]\n",
      "Upload successful: encoder_4.tar (133MB)\n",
      "Starting upload for file logs.tar\n",
      "100%|███████████████████████████████████████| 2.37M/2.37M [00:04<00:00, 569kB/s]\n",
      "Upload successful: logs.tar (2MB)\n",
      "Starting upload for file conv1d-autoencoder.ipynb\n",
      "100%|████████████████████████████████████████| 114k/114k [00:07<00:00, 15.7kB/s]\n",
      "Upload successful: conv1d-autoencoder.ipynb (114KB)\n",
      "Starting upload for file oof_wavenet_probs.npy\n",
      "100%|██████████████████████████████████████| 38.1M/38.1M [00:06<00:00, 6.39MB/s]\n",
      "Upload successful: oof_wavenet_probs.npy (38MB)\n",
      "Starting upload for file test_enc.npy\n",
      "100%|████████████████████████████████████████| 125k/125k [00:04<00:00, 25.9kB/s]\n",
      "Upload successful: test_enc.npy (125KB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/jessepinkman21/ion-switching-group-autoencoder\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -p group-autoencoder -r tar "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
